{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-cuofaos1 because the default path (/home/asrock/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, csv\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from utilities import one_hot_encoding, read_train_data, read_label_data, show_train_history\n",
    "from utilities import build_vgg_model, build_resnet50_model, build_inceptionv3_model\n",
    "\n",
    "SIZE = 10000\n",
    "MODEL_FOLDER = \"model/\"\n",
    "WIDTH = 140\n",
    "HEIGHT = 48\n",
    "IMG_SIZE = WIDTH if WIDTH > HEIGHT else HEIGHT\n",
    "NUM_DIGIT = 4\n",
    "PROCESSED_FOLDER = \"processed/\"\n",
    "LABEL_CSV_FILE = 'label.csv'\n",
    "allowedChars = '234579ACFHKMNPQRTYZ';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 140, 140, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 146, 146, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 70, 70, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 70, 70, 64)   256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 70, 70, 64)   0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 72, 72, 64)   0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 35, 35, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 35, 35, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 35, 35, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 35, 35, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 35, 35, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 35, 35, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 35, 35, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 35, 35, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 35, 35, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 35, 35, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 35, 35, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 35, 35, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 35, 35, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 35, 35, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 35, 35, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 35, 35, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 35, 35, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 35, 35, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 35, 35, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 35, 35, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 35, 35, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 35, 35, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 35, 35, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 35, 35, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 35, 35, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 35, 35, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 35, 35, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 35, 35, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 35, 35, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 35, 35, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 35, 35, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 35, 35, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 35, 35, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 18, 18, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 18, 18, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 18, 18, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 18, 18, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 18, 18, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 18, 18, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 18, 18, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 18, 18, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 18, 18, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 18, 18, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 18, 18, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 18, 18, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 18, 18, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 18, 18, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 18, 18, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 18, 18, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 18, 18, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 18, 18, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 18, 18, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 18, 18, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 18, 18, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 18, 18, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 18, 18, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 18, 18, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 18, 18, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 18, 18, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 18, 18, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 18, 18, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 18, 18, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 18, 18, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 18, 18, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 18, 18, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 18, 18, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 18, 18, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 18, 18, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 9, 9, 256)    131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 9, 9, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 9, 9, 256)    590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 9, 9, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 9, 9, 1024)   525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 9, 9, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 9, 9, 1024)   0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 9, 9, 1024)   0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 9, 9, 256)    262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 9, 9, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 9, 9, 256)    590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 9, 9, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 9, 9, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 9, 9, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 9, 9, 1024)   0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 9, 9, 256)    262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 9, 9, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 9, 9, 256)    590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 9, 9, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 9, 9, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 9, 9, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 9, 9, 1024)   0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 9, 9, 256)    262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 9, 9, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 9, 9, 256)    590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 9, 9, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 9, 9, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 9, 9, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 9, 9, 1024)   0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 9, 9, 256)    262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 9, 9, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 9, 9, 256)    590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 9, 9, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 9, 9, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 9, 9, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 9, 9, 1024)   0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 9, 9, 256)    262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 9, 9, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 9, 9, 256)    590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 9, 9, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 9, 9, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 9, 9, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 9, 9, 1024)   4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 9, 9, 1024)   0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 9, 9, 1024)   0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 5, 5, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 5, 5, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 5, 5, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 5, 5, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 51200)        0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 51200)        0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "digit1 (Dense)                  (None, 19)           972819      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "digit2 (Dense)                  (None, 19)           972819      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "digit3 (Dense)                  (None, 19)           972819      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "digit4 (Dense)                  (None, 19)           972819      dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,478,988\n",
      "Trainable params: 27,425,868\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = build_vgg_model(IMG_SIZE, allowedChars, NUM_DIGIT)\n",
    "# model = build_inceptionv3_model(IMG_SIZE, allowedChars, NUM_DIGIT)\n",
    "model = build_resnet50_model(IMG_SIZE, allowedChars, NUM_DIGIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading training data...\n",
      "Reading completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading training data...\")\n",
    "\n",
    "train_data = read_train_data(PROCESSED_FOLDER, SIZE)\n",
    "train_label = read_label_data(LABEL_CSV_FILE, allowedChars, NUM_DIGIT, SIZE)\n",
    "\n",
    "print(\"Reading completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = MODEL_FOLDER + \"{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_digit4_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, mode='auto')\n",
    "tensorBoard = TensorBoard(log_dir = 'logs', histogram_freq = 1)\n",
    "callbacks_list = [tensorBoard, earlystop, checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(\"thsrc_cnn_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  1/160 [..............................] - ETA: 0s - loss: 22.7267 - digit1_loss: 5.2869 - digit2_loss: 5.5707 - digit3_loss: 6.0621 - digit4_loss: 5.8069 - digit1_accuracy: 0.0800 - digit2_accuracy: 0.0400 - digit3_accuracy: 0.0400 - digit4_accuracy: 0.0200WARNING:tensorflow:From /home/asrock/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "160/160 [==============================] - ETA: 0s - loss: 4.9374 - digit1_loss: 1.2767 - digit2_loss: 1.3947 - digit3_loss: 1.3113 - digit4_loss: 0.9547 - digit1_accuracy: 0.6684 - digit2_accuracy: 0.6467 - digit3_accuracy: 0.6696 - digit4_accuracy: 0.7772\n",
      "Epoch 00001: val_digit4_accuracy improved from -inf to 0.05100, saving model to model/01-4.94-12.02.hdf5\n",
      "160/160 [==============================] - 441s 3s/step - loss: 4.9374 - digit1_loss: 1.2767 - digit2_loss: 1.3947 - digit3_loss: 1.3113 - digit4_loss: 0.9547 - digit1_accuracy: 0.6684 - digit2_accuracy: 0.6467 - digit3_accuracy: 0.6696 - digit4_accuracy: 0.7772 - val_loss: 12.0219 - val_digit1_loss: 3.0229 - val_digit2_loss: 3.0128 - val_digit3_loss: 3.0092 - val_digit4_loss: 2.9770 - val_digit1_accuracy: 0.0490 - val_digit2_accuracy: 0.0630 - val_digit3_accuracy: 0.0525 - val_digit4_accuracy: 0.0510\n",
      "Epoch 2/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.3862 - digit1_loss: 0.1286 - digit2_loss: 0.1145 - digit3_loss: 0.0911 - digit4_loss: 0.0519 - digit1_accuracy: 0.9689 - digit2_accuracy: 0.9693 - digit3_accuracy: 0.9770 - digit4_accuracy: 0.9916\n",
      "Epoch 00002: val_digit4_accuracy improved from 0.05100 to 0.06500, saving model to model/02-0.39-11.91.hdf5\n",
      "160/160 [==============================] - 344s 2s/step - loss: 0.3862 - digit1_loss: 0.1286 - digit2_loss: 0.1145 - digit3_loss: 0.0911 - digit4_loss: 0.0519 - digit1_accuracy: 0.9689 - digit2_accuracy: 0.9693 - digit3_accuracy: 0.9770 - digit4_accuracy: 0.9916 - val_loss: 11.9138 - val_digit1_loss: 2.9731 - val_digit2_loss: 2.9856 - val_digit3_loss: 2.9842 - val_digit4_loss: 2.9709 - val_digit1_accuracy: 0.0515 - val_digit2_accuracy: 0.0635 - val_digit3_accuracy: 0.0535 - val_digit4_accuracy: 0.0650\n",
      "Epoch 3/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.1678 - digit1_loss: 0.0686 - digit2_loss: 0.0431 - digit3_loss: 0.0296 - digit4_loss: 0.0266 - digit1_accuracy: 0.9818 - digit2_accuracy: 0.9885 - digit3_accuracy: 0.9939 - digit4_accuracy: 0.9954\n",
      "Epoch 00003: val_digit4_accuracy improved from 0.06500 to 0.29400, saving model to model/03-0.17-11.33.hdf5\n",
      "160/160 [==============================] - 324s 2s/step - loss: 0.1678 - digit1_loss: 0.0686 - digit2_loss: 0.0431 - digit3_loss: 0.0296 - digit4_loss: 0.0266 - digit1_accuracy: 0.9818 - digit2_accuracy: 0.9885 - digit3_accuracy: 0.9939 - digit4_accuracy: 0.9954 - val_loss: 11.3253 - val_digit1_loss: 2.8943 - val_digit2_loss: 2.8559 - val_digit3_loss: 2.8533 - val_digit4_loss: 2.7219 - val_digit1_accuracy: 0.0635 - val_digit2_accuracy: 0.0970 - val_digit3_accuracy: 0.1195 - val_digit4_accuracy: 0.2940\n",
      "Epoch 4/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0842 - digit1_loss: 0.0284 - digit2_loss: 0.0256 - digit3_loss: 0.0199 - digit4_loss: 0.0104 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9923 - digit3_accuracy: 0.9944 - digit4_accuracy: 0.9979\n",
      "Epoch 00004: val_digit4_accuracy improved from 0.29400 to 0.81200, saving model to model/04-0.08-5.52.hdf5\n",
      "160/160 [==============================] - 270s 2s/step - loss: 0.0842 - digit1_loss: 0.0284 - digit2_loss: 0.0256 - digit3_loss: 0.0199 - digit4_loss: 0.0104 - digit1_accuracy: 0.9921 - digit2_accuracy: 0.9923 - digit3_accuracy: 0.9944 - digit4_accuracy: 0.9979 - val_loss: 5.5188 - val_digit1_loss: 1.7875 - val_digit2_loss: 1.4380 - val_digit3_loss: 1.3698 - val_digit4_loss: 0.9235 - val_digit1_accuracy: 0.4485 - val_digit2_accuracy: 0.6165 - val_digit3_accuracy: 0.6020 - val_digit4_accuracy: 0.8120\n",
      "Epoch 5/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0643 - digit1_loss: 0.0189 - digit2_loss: 0.0223 - digit3_loss: 0.0153 - digit4_loss: 0.0078 - digit1_accuracy: 0.9961 - digit2_accuracy: 0.9931 - digit3_accuracy: 0.9960 - digit4_accuracy: 0.9984\n",
      "Epoch 00005: val_digit4_accuracy improved from 0.81200 to 0.98500, saving model to model/05-0.06-0.81.hdf5\n",
      "160/160 [==============================] - 268s 2s/step - loss: 0.0643 - digit1_loss: 0.0189 - digit2_loss: 0.0223 - digit3_loss: 0.0153 - digit4_loss: 0.0078 - digit1_accuracy: 0.9961 - digit2_accuracy: 0.9931 - digit3_accuracy: 0.9960 - digit4_accuracy: 0.9984 - val_loss: 0.8092 - val_digit1_loss: 0.3063 - val_digit2_loss: 0.2409 - val_digit3_loss: 0.1963 - val_digit4_loss: 0.0658 - val_digit1_accuracy: 0.9195 - val_digit2_accuracy: 0.9300 - val_digit3_accuracy: 0.9450 - val_digit4_accuracy: 0.9850\n",
      "Epoch 6/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0654 - digit1_loss: 0.0259 - digit2_loss: 0.0146 - digit3_loss: 0.0169 - digit4_loss: 0.0080 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9950 - digit3_accuracy: 0.9946 - digit4_accuracy: 0.9985\n",
      "Epoch 00006: val_digit4_accuracy improved from 0.98500 to 0.99100, saving model to model/06-0.07-0.31.hdf5\n",
      "160/160 [==============================] - 330s 2s/step - loss: 0.0654 - digit1_loss: 0.0259 - digit2_loss: 0.0146 - digit3_loss: 0.0169 - digit4_loss: 0.0080 - digit1_accuracy: 0.9926 - digit2_accuracy: 0.9950 - digit3_accuracy: 0.9946 - digit4_accuracy: 0.9985 - val_loss: 0.3123 - val_digit1_loss: 0.0869 - val_digit2_loss: 0.1080 - val_digit3_loss: 0.0788 - val_digit4_loss: 0.0387 - val_digit1_accuracy: 0.9765 - val_digit2_accuracy: 0.9660 - val_digit3_accuracy: 0.9775 - val_digit4_accuracy: 0.9910\n",
      "Epoch 7/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0593 - digit1_loss: 0.0195 - digit2_loss: 0.0187 - digit3_loss: 0.0109 - digit4_loss: 0.0103 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9950 - digit3_accuracy: 0.9967 - digit4_accuracy: 0.9977\n",
      "Epoch 00007: val_digit4_accuracy improved from 0.99100 to 0.99950, saving model to model/07-0.06-0.14.hdf5\n",
      "160/160 [==============================] - 349s 2s/step - loss: 0.0593 - digit1_loss: 0.0195 - digit2_loss: 0.0187 - digit3_loss: 0.0109 - digit4_loss: 0.0103 - digit1_accuracy: 0.9949 - digit2_accuracy: 0.9950 - digit3_accuracy: 0.9967 - digit4_accuracy: 0.9977 - val_loss: 0.1436 - val_digit1_loss: 0.0601 - val_digit2_loss: 0.0413 - val_digit3_loss: 0.0396 - val_digit4_loss: 0.0025 - val_digit1_accuracy: 0.9815 - val_digit2_accuracy: 0.9875 - val_digit3_accuracy: 0.9895 - val_digit4_accuracy: 0.9995\n",
      "Epoch 8/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0838 - digit1_loss: 0.0401 - digit2_loss: 0.0246 - digit3_loss: 0.0101 - digit4_loss: 0.0090 - digit1_accuracy: 0.9883 - digit2_accuracy: 0.9927 - digit3_accuracy: 0.9967 - digit4_accuracy: 0.9973\n",
      "Epoch 00008: val_digit4_accuracy did not improve from 0.99950\n",
      "160/160 [==============================] - 253s 2s/step - loss: 0.0838 - digit1_loss: 0.0401 - digit2_loss: 0.0246 - digit3_loss: 0.0101 - digit4_loss: 0.0090 - digit1_accuracy: 0.9883 - digit2_accuracy: 0.9927 - digit3_accuracy: 0.9967 - digit4_accuracy: 0.9973 - val_loss: 0.1636 - val_digit1_loss: 0.0481 - val_digit2_loss: 0.0586 - val_digit3_loss: 0.0497 - val_digit4_loss: 0.0073 - val_digit1_accuracy: 0.9865 - val_digit2_accuracy: 0.9805 - val_digit3_accuracy: 0.9895 - val_digit4_accuracy: 0.9985\n",
      "Epoch 9/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0872 - digit1_loss: 0.0331 - digit2_loss: 0.0260 - digit3_loss: 0.0193 - digit4_loss: 0.0088 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9921 - digit3_accuracy: 0.9945 - digit4_accuracy: 0.9974\n",
      "Epoch 00009: val_digit4_accuracy did not improve from 0.99950\n",
      "160/160 [==============================] - 253s 2s/step - loss: 0.0872 - digit1_loss: 0.0331 - digit2_loss: 0.0260 - digit3_loss: 0.0193 - digit4_loss: 0.0088 - digit1_accuracy: 0.9904 - digit2_accuracy: 0.9921 - digit3_accuracy: 0.9945 - digit4_accuracy: 0.9974 - val_loss: 0.1523 - val_digit1_loss: 0.0381 - val_digit2_loss: 0.0720 - val_digit3_loss: 0.0348 - val_digit4_loss: 0.0074 - val_digit1_accuracy: 0.9855 - val_digit2_accuracy: 0.9840 - val_digit3_accuracy: 0.9900 - val_digit4_accuracy: 0.9995\n",
      "Epoch 10/10\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.0856 - digit1_loss: 0.0373 - digit2_loss: 0.0199 - digit3_loss: 0.0162 - digit4_loss: 0.0121 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9945 - digit3_accuracy: 0.9949 - digit4_accuracy: 0.9970\n",
      "Epoch 00010: val_digit4_accuracy did not improve from 0.99950\n",
      "160/160 [==============================] - 286s 2s/step - loss: 0.0856 - digit1_loss: 0.0373 - digit2_loss: 0.0199 - digit3_loss: 0.0162 - digit4_loss: 0.0121 - digit1_accuracy: 0.9895 - digit2_accuracy: 0.9945 - digit3_accuracy: 0.9949 - digit4_accuracy: 0.9970 - val_loss: 0.2051 - val_digit1_loss: 0.0935 - val_digit2_loss: 0.0688 - val_digit3_loss: 0.0381 - val_digit4_loss: 0.0047 - val_digit1_accuracy: 0.9815 - val_digit2_accuracy: 0.9865 - val_digit3_accuracy: 0.9890 - val_digit4_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_label, validation_split=0.2, batch_size=50, epochs=10, verbose=1, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(history, 'digit1_accuracy', 'val_digit1_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
