{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "WIDTH = 140\n",
    "HEIGHT = 48\n",
    "\n",
    "CAPTCHA_FOLDER = \"captcha/\"\n",
    "PROCESSED_FOLDER = \"processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgDenoise(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    dst = cv2.fastNlMeansDenoisingColored(img, None, 30, 30, 7, 21)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2Gray(img):\n",
    "    ret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRegression(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img[:, 14:WIDTH - 7] = 0\n",
    "    imagedata = np.where(img == 255)\n",
    "\n",
    "    X = np.array([imagedata[1]])\n",
    "    Y = HEIGHT - imagedata[0]\n",
    "\n",
    "    poly_reg = PolynomialFeatures(degree = 2)\n",
    "    X_ = poly_reg.fit_transform(X.T)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_, Y)\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePolynomial(img, regr):\n",
    "    X2 = np.array([[i for i in range(0, WIDTH)]])\n",
    "    poly_reg = PolynomialFeatures(degree = 2)\n",
    "    X2_ = poly_reg.fit_transform(X2.T)\n",
    "    offset = 4\n",
    "\n",
    "    newimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    for ele in np.column_stack([regr.predict(X2_).round(2), X2[0]]):\n",
    "        pos = HEIGHT - int(ele[0])\n",
    "        newimg[pos - offset:pos + offset, int(ele[1])] = 255 - newimg[pos - offset:pos + offset, int(ele[1])]\n",
    "\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPadding(img):\n",
    "    size = (WIDTH - HEIGHT) // 2\n",
    "    const = cv2.copyMakeBorder(img, size, size, 0, 0, cv2.BORDER_CONSTANT, value = [0,0,0])\n",
    "    return const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanceText(img):\n",
    "    \"\"\"\n",
    "    針對文字識別優化的圖片增強\n",
    "    \"\"\"\n",
    "    # 1. 自適應直方圖均衡化\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "\n",
    "    # 2. 雙邊濾波保邊去噪\n",
    "    img = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "    # 3. 自適應閾值二值化\n",
    "    binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # 4. 形態學操作清理噪點\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 5. 文字筆劃增強\n",
    "    kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    binary = cv2.dilate(binary, kernel_dilate, iterations=1)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def advancedTextEnhancement(img):\n",
    "    \"\"\"\n",
    "    更進階的文字增強方法\n",
    "    \"\"\"\n",
    "    # 1. Gamma校正增強對比度\n",
    "    gamma = 1.2\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    img = cv2.LUT(img, table)\n",
    "\n",
    "    # 2. 銳化濾波\n",
    "    kernel_sharp = np.array([[-1,-1,-1],\n",
    "                            [-1, 9,-1],\n",
    "                            [-1,-1,-1]])\n",
    "    img = cv2.filter2D(img, -1, kernel_sharp)\n",
    "\n",
    "    # 3. 多尺度Retinex增強\n",
    "    img = multiScaleRetinex(img)\n",
    "\n",
    "    # 4. 自適應二值化 (Otsu + Gaussian)\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 5. 連通組件清理\n",
    "    binary = cleanSmallComponents(binary)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def multiScaleRetinex(img, scales=[15, 80, 250]):\n",
    "    \"\"\"\n",
    "    多尺度Retinex演算法增強圖片\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32) + 1.0\n",
    "    retinex = np.zeros_like(img)\n",
    "\n",
    "    for scale in scales:\n",
    "        gaussian = cv2.GaussianBlur(img, (0, 0), scale)\n",
    "        retinex += np.log10(img) - np.log10(gaussian)\n",
    "\n",
    "    retinex = retinex / len(scales)\n",
    "    retinex = (retinex - np.min(retinex)) / (np.max(retinex) - np.min(retinex)) * 255\n",
    "    return retinex.astype(np.uint8)\n",
    "\n",
    "def cleanSmallComponents(binary, min_size=50):\n",
    "    \"\"\"\n",
    "    清理小的連通組件\n",
    "    \"\"\"\n",
    "    # 找到連通組件\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
    "\n",
    "    # 創建清理後的圖片\n",
    "    cleaned = np.zeros_like(binary)\n",
    "\n",
    "    for i in range(1, num_labels):  # 跳過背景(標籤0)\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            cleaned[labels == i] = 255\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def textSpecificBinarization(img):\n",
    "    \"\"\"\n",
    "    專門針對文字的二值化方法\n",
    "    \"\"\"\n",
    "    # 1. 預處理\n",
    "    img = cv2.medianBlur(img, 3)\n",
    "\n",
    "    # 2. 嘗試多種閾值方法並選擇最佳\n",
    "    methods = []\n",
    "\n",
    "    # Otsu\n",
    "    _, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    methods.append(otsu)\n",
    "\n",
    "    # 自適應閾值 (均值)\n",
    "    adaptive_mean = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                         cv2.THRESH_BINARY, 15, 8)\n",
    "    methods.append(adaptive_mean)\n",
    "\n",
    "    # 自適應閾值 (高斯)\n",
    "    adaptive_gaussian = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY, 15, 8)\n",
    "    methods.append(adaptive_gaussian)\n",
    "\n",
    "    # 選擇文字區域最清晰的方法\n",
    "    best_method = selectBestBinarization(methods, img)\n",
    "\n",
    "    return best_method\n",
    "\n",
    "def selectBestBinarization(methods, original):\n",
    "    \"\"\"\n",
    "    基於文字清晰度選擇最佳二值化方法\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for method in methods:\n",
    "        # 計算邊緣強度作為清晰度指標\n",
    "        edges = cv2.Canny(method, 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "\n",
    "        # 計算連通組件數量 (適中的組件數量通常對應好的文字分割)\n",
    "        num_labels, _ = cv2.connectedComponents(method)\n",
    "        component_score = 1.0 / (1.0 + abs(num_labels - 10))  # 假設理想組件數為10\n",
    "\n",
    "        # 綜合評分\n",
    "        score = edge_density * 0.7 + component_score * 0.3\n",
    "        scores.append(score)\n",
    "\n",
    "    best_idx = np.argmax(scores)\n",
    "    return methods[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = [[0] * 2 for i in range(100)]\n",
    "for i in range(100):\n",
    "    dic[i][0]=25\n",
    "    dic[i][1]=25\n",
    "dic[50][0]=26\n",
    "dic[50][1]=24\n",
    "dic[48][0]=23\n",
    "dic[48][1]=30\n",
    "dic[46][0]=27\n",
    "dic[46][1]=25\n",
    "dic[45][0]=21\n",
    "dic[45][1]=30\n",
    "\n",
    "def preprocessing(from_filename, to_filename):\n",
    "    img = cv2.imread(from_filename)\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret1,img_ = cv2.threshold(img,1234, 255,cv2.THRESH_OTSU)\n",
    "    ret,img = cv2.threshold(img,ret1+5, 255,cv2.THRESH_BINARY)\n",
    "\n",
    "    img = cv2.fastNlMeansDenoising(img, None, 50.0, 7, 50)\n",
    "    ret1,img = cv2.threshold(img,1234, 255,cv2.THRESH_OTSU)\n",
    "\n",
    "    def find_point(mat):\n",
    "        start_index=0\n",
    "        end_index=mat.shape[0]-1\n",
    "        for i in range(mat.shape[0]):\n",
    "            if np.all(mat[i]==0) and start_index==0:\n",
    "                start_index=i\n",
    "            elif np.all(mat[i]==0)==False and start_index!=0:\n",
    "                end_index=i-1\n",
    "                break\n",
    "        return int(start_index+round((end_index-start_index+1)/2))\n",
    "\n",
    "    left=img[:, :5]\n",
    "    right=img[:, -5:]\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3, 3))\n",
    "    left=cv2.erode(left, kernel)\n",
    "    right=cv2.erode(right, kernel)\n",
    "    ret, left=cv2.threshold(left,1234, 255,cv2.THRESH_OTSU)\n",
    "    ret, right=cv2.threshold(right,1234, 255,cv2.THRESH_OTSU)\n",
    "\n",
    "    left_point=find_point(left)\n",
    "    right_point=find_point(right)\n",
    "    new_x=[i for i in range(img.shape[1])]\n",
    "    new_y=np.poly1d(np.polyfit([0, (img.shape[1]-1)/2, img.shape[1]-1], [left_point, right_point+((left_point-right_point)/2)-6, right_point], 2))(new_x)\n",
    "    line_template=np.full(img.shape, 255, dtype=np.uint8)\n",
    "    for x_, y_ in zip(new_x, new_y):\n",
    "        y_=int(round(y_))\n",
    "        color=255-img[y_][x_]\n",
    "        if color==255:\n",
    "            cv2.line(line_template, (x_, y_), (x_, y_), (0, 0, 0), 3, cv2.LINE_AA)\n",
    "        elif color==0:\n",
    "            cv2.line(line_template, (x_, y_), (x_, y_), (0, 0, 0), 3, cv2.LINE_AA)\n",
    "    line_template=line_template.astype(np.uint8)\n",
    "\n",
    "    for r in range(img.shape[0]):\n",
    "        for c in range(img.shape[1]):\n",
    "            if line_template[r][c]==0 and img[r][c]==0:\n",
    "                img[r][c]=255\n",
    "            elif line_template[r][c]==0 and img[r][c]==255:\n",
    "                img[r][c]=0\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(1, 3))\n",
    "    img=cv2.erode(img, kernel)\n",
    "    img=cv2.dilate(img, kernel)\n",
    "    img=cv2.dilate(img, kernel)\n",
    "    img=cv2.erode(img, kernel)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(3, 1))\n",
    "    img=cv2.dilate(img, kernel)\n",
    "    img=cv2.erode(img, kernel)\n",
    "\n",
    "    h=200\n",
    "    w=int(img.shape[1]*h/img.shape[0])\n",
    "    img = cv2.resize(img, (w, h), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    bordersize = 100\n",
    "    img = cv2.copyMakeBorder(\n",
    "        img,\n",
    "        top=bordersize,\n",
    "        bottom=bordersize,\n",
    "        left=bordersize,\n",
    "        right=bordersize,\n",
    "        borderType=cv2.BORDER_CONSTANT,\n",
    "        value=[255, 255, 255]\n",
    "    )\n",
    "\n",
    "    cv2.imwrite(to_filename, img)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
