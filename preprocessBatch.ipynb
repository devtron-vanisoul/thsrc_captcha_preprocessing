{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import binarize\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "WIDTH = 140\n",
    "HEIGHT = 48\n",
    "\n",
    "CAPTCHA_FOLDER = \"captcha/\"\n",
    "PROCESSED_FOLDER = \"processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgDenoise(filename):\n",
    "    img = cv2.imread(filename)\n",
    "    dst = cv2.fastNlMeansDenoisingColored(img, None, 30, 30, 7, 21)\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2Gray(img):\n",
    "    ret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRegression(img):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img[:, 14:WIDTH - 7] = 0\n",
    "    imagedata = np.where(img == 255)\n",
    "\n",
    "    X = np.array([imagedata[1]])\n",
    "    Y = HEIGHT - imagedata[0]\n",
    "\n",
    "    poly_reg = PolynomialFeatures(degree = 2)\n",
    "    X_ = poly_reg.fit_transform(X.T)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_, Y)\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dePolynomial(img, regr):\n",
    "    X2 = np.array([[i for i in range(0, WIDTH)]])\n",
    "    poly_reg = PolynomialFeatures(degree = 2)\n",
    "    X2_ = poly_reg.fit_transform(X2.T)\n",
    "    offset = 4\n",
    "\n",
    "    newimg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    for ele in np.column_stack([regr.predict(X2_).round(2), X2[0]]):\n",
    "        pos = HEIGHT - int(ele[0])\n",
    "        newimg[pos - offset:pos + offset, int(ele[1])] = 255 - newimg[pos - offset:pos + offset, int(ele[1])]\n",
    "\n",
    "    return newimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addPadding(img):\n",
    "    size = (WIDTH - HEIGHT) // 2\n",
    "    const = cv2.copyMakeBorder(img, size, size, 0, 0, cv2.BORDER_CONSTANT, value = [0,0,0])\n",
    "    return const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanceText(img):\n",
    "    \"\"\"\n",
    "    針對文字識別優化的圖片增強\n",
    "    \"\"\"\n",
    "    # 1. 自適應直方圖均衡化\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    img = clahe.apply(img)\n",
    "\n",
    "    # 2. 雙邊濾波保邊去噪\n",
    "    img = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "    # 3. 自適應閾值二值化\n",
    "    binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "    # 4. 形態學操作清理噪點\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 5. 文字筆劃增強\n",
    "    kernel_dilate = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "    binary = cv2.dilate(binary, kernel_dilate, iterations=1)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def advancedTextEnhancement(img):\n",
    "    \"\"\"\n",
    "    更進階的文字增強方法\n",
    "    \"\"\"\n",
    "    # 1. Gamma校正增強對比度\n",
    "    gamma = 1.2\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    img = cv2.LUT(img, table)\n",
    "\n",
    "    # 2. 銳化濾波\n",
    "    kernel_sharp = np.array([[-1,-1,-1],\n",
    "                            [-1, 9,-1],\n",
    "                            [-1,-1,-1]])\n",
    "    img = cv2.filter2D(img, -1, kernel_sharp)\n",
    "\n",
    "    # 3. 多尺度Retinex增強\n",
    "    img = multiScaleRetinex(img)\n",
    "\n",
    "    # 4. 自適應二值化 (Otsu + Gaussian)\n",
    "    blur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 5. 連通組件清理\n",
    "    binary = cleanSmallComponents(binary)\n",
    "\n",
    "    return binary\n",
    "\n",
    "def multiScaleRetinex(img, scales=[15, 80, 250]):\n",
    "    \"\"\"\n",
    "    多尺度Retinex演算法增強圖片\n",
    "    \"\"\"\n",
    "    img = img.astype(np.float32) + 1.0\n",
    "    retinex = np.zeros_like(img)\n",
    "\n",
    "    for scale in scales:\n",
    "        gaussian = cv2.GaussianBlur(img, (0, 0), scale)\n",
    "        retinex += np.log10(img) - np.log10(gaussian)\n",
    "\n",
    "    retinex = retinex / len(scales)\n",
    "    retinex = (retinex - np.min(retinex)) / (np.max(retinex) - np.min(retinex)) * 255\n",
    "    return retinex.astype(np.uint8)\n",
    "\n",
    "def cleanSmallComponents(binary, min_size=50):\n",
    "    \"\"\"\n",
    "    清理小的連通組件\n",
    "    \"\"\"\n",
    "    # 找到連通組件\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
    "\n",
    "    # 創建清理後的圖片\n",
    "    cleaned = np.zeros_like(binary)\n",
    "\n",
    "    for i in range(1, num_labels):  # 跳過背景(標籤0)\n",
    "        if stats[i, cv2.CC_STAT_AREA] >= min_size:\n",
    "            cleaned[labels == i] = 255\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def textSpecificBinarization(img):\n",
    "    \"\"\"\n",
    "    專門針對文字的二值化方法\n",
    "    \"\"\"\n",
    "    # 1. 預處理\n",
    "    img = cv2.medianBlur(img, 3)\n",
    "\n",
    "    # 2. 嘗試多種閾值方法並選擇最佳\n",
    "    methods = []\n",
    "\n",
    "    # Otsu\n",
    "    _, otsu = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    methods.append(otsu)\n",
    "\n",
    "    # 自適應閾值 (均值)\n",
    "    adaptive_mean = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                         cv2.THRESH_BINARY, 15, 8)\n",
    "    methods.append(adaptive_mean)\n",
    "\n",
    "    # 自適應閾值 (高斯)\n",
    "    adaptive_gaussian = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                            cv2.THRESH_BINARY, 15, 8)\n",
    "    methods.append(adaptive_gaussian)\n",
    "\n",
    "    # 選擇文字區域最清晰的方法\n",
    "    best_method = selectBestBinarization(methods, img)\n",
    "\n",
    "    return best_method\n",
    "\n",
    "def selectBestBinarization(methods, original):\n",
    "    \"\"\"\n",
    "    基於文字清晰度選擇最佳二值化方法\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for method in methods:\n",
    "        # 計算邊緣強度作為清晰度指標\n",
    "        edges = cv2.Canny(method, 50, 150)\n",
    "        edge_density = np.sum(edges > 0) / edges.size\n",
    "\n",
    "        # 計算連通組件數量 (適中的組件數量通常對應好的文字分割)\n",
    "        num_labels, _ = cv2.connectedComponents(method)\n",
    "        component_score = 1.0 / (1.0 + abs(num_labels - 10))  # 假設理想組件數為10\n",
    "\n",
    "        # 綜合評分\n",
    "        score = edge_density * 0.7 + component_score * 0.3\n",
    "        scores.append(score)\n",
    "\n",
    "    best_idx = np.argmax(scores)\n",
    "    return methods[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = [[0] * 2 for i in range(100)]\n",
    "for i in range(100):\n",
    "    dic[i][0]=25\n",
    "    dic[i][1]=25\n",
    "dic[50][0]=26\n",
    "dic[50][1]=24\n",
    "dic[48][0]=23\n",
    "dic[48][1]=30\n",
    "dic[46][0]=27\n",
    "dic[46][1]=25\n",
    "dic[45][0]=21\n",
    "dic[45][1]=30\n",
    "\n",
    "def preprocessing(from_filename, to_filename):\n",
    "    # 載入影像\n",
    "    img = cv2.imread(from_filename)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"找不到檔案: {from_filename}\")\n",
    "\n",
    "    height1, width1, _ = img.shape\n",
    "\n",
    "    # 降噪\n",
    "    dst = cv2.fastNlMeansDenoisingColored(img, None, 31, 31, 7, 21)\n",
    "\n",
    "    # 儲存降噪圖片到暫存（避免白邊）\n",
    "    img_bgr = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # 以 figsize=(width1, height1) 為基礎計算最終輸出解析度\n",
    "    output_width = int(width1 * 10)   # dpi=10\n",
    "    output_height = int(height1 * 10)\n",
    "\n",
    "    # 重新調整圖像大小\n",
    "    img_resized = cv2.resize(img_bgr, (output_width, output_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 讀取降噪後圖片再黑白化\n",
    "    ret, thresh = cv2.threshold(img_resized, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    height, width, _ = thresh.shape\n",
    "    imgarr = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 區域遮罩處理\n",
    "    imgarr[:, 100:width-40] = 0\n",
    "    imagedata = np.where(imgarr == 255)\n",
    "    X = np.array([imagedata[1]])\n",
    "    Y = height - imagedata[0]\n",
    "\n",
    "    # 曲線擬合\n",
    "    poly_reg = PolynomialFeatures(degree=2)\n",
    "    X_ = poly_reg.fit_transform(X.T)\n",
    "    regr = LinearRegression()\n",
    "    regr.fit(X_, Y)\n",
    "\n",
    "    # 回歸線預測\n",
    "    X2 = np.array([[i for i in range(0, width)]])\n",
    "    X2_ = poly_reg.fit_transform(X2.T)\n",
    "\n",
    "    for ele in np.column_stack([regr.predict(X2_).round(0), X2[0]]):\n",
    "        pos = height - int(ele[0])\n",
    "        start_y = max(pos - int(dic[height1][0]), 0)\n",
    "        end_y = min(pos + int(dic[height1][1]), height)\n",
    "        thresh[start_y:end_y, int(ele[1])] = 255 - thresh[start_y:end_y, int(ele[1])]\n",
    "\n",
    "    # 調整大小並儲存\n",
    "    thresh = 255 - thresh\n",
    "    newdst = cv2.resize(thresh, (140, 48), interpolation=cv2.INTER_AREA)\n",
    "    if newdst.dtype != 'uint8':\n",
    "        newdst = (newdst * 255).astype('uint8')  # 若原圖是 0~1 浮點數\n",
    "\n",
    "    # 儲存圖片\n",
    "    cv2.imwrite(to_filename, newdst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "# ignore existing image\n",
    "while True:\n",
    "    i += 1\n",
    "    filename = PROCESSED_FOLDER + str(i) + '.jpg'\n",
    "    if not os.path.isfile(filename):\n",
    "        i -= 1\n",
    "        break\n",
    "\n",
    "print(\"start to process image from index: \" + str(i + 1))\n",
    "\n",
    "while True:\n",
    "    i += 1\n",
    "    filename = CAPTCHA_FOLDER + str(i) + '.jpg'\n",
    "    if not os.path.isfile(filename):\n",
    "        break\n",
    "    preprocessing(filename, PROCESSED_FOLDER + str(i) + '.jpg')\n",
    "    print(\"i: \", i)\n",
    "\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
